{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Pipeline\n",
    "## Satellite Imagery-Based Property Valuation\n",
    "\n",
    "This notebook covers:\n",
    "1. Tabular Baseline Model\n",
    "2. Multimodal Fusion Model\n",
    "3. Model Comparison\n",
    "4. Grad-CAM Explainability\n",
    "5. Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "PROCESSED_DATA_DIR = Path(\"data/processed\")\n",
    "OUTPUT_DIR = Path(\"outputs\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tabular data\n",
    "data = np.load(PROCESSED_DATA_DIR / \"train_processed.npz\", allow_pickle=True)\n",
    "\n",
    "X_train = data[\"X_train\"]\n",
    "y_train = data[\"y_train\"].reshape(-1)\n",
    "X_val = data[\"X_val\"]\n",
    "y_val = data[\"y_val\"].reshape(-1)\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Validation samples: {X_val.shape[0]}\")\n",
    "print(f\"Tabular features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image embeddings\n",
    "emb_train = np.load(PROCESSED_DATA_DIR / \"img_emb_train.npy\")\n",
    "emb_val = np.load(PROCESSED_DATA_DIR / \"img_emb_val.npy\")\n",
    "\n",
    "print(f\"Train embeddings: {emb_train.shape}\")\n",
    "print(f\"Val embeddings: {emb_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessor for inverse transform\n",
    "with open(PROCESSED_DATA_DIR / \"preprocessor.pkl\", \"rb\") as f:\n",
    "    preprocessor = pickle.load(f)\n",
    "\n",
    "target_scaler = preprocessor[\"target_scaler\"]\n",
    "print(\"Preprocessor loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tabular Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Tabular Baseline Model...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Train HistGradientBoostingRegressor on tabular data only\n",
    "baseline_model = HistGradientBoostingRegressor(\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    max_iter=500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "baseline_model.fit(X_train, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline\n",
    "pred_val_scaled = baseline_model.predict(X_val).reshape(-1, 1)\n",
    "\n",
    "# Inverse transform to get actual prices\n",
    "y_val_price = target_scaler.inverse_transform(y_val.reshape(-1, 1)).reshape(-1)\n",
    "pred_val_price = target_scaler.inverse_transform(pred_val_scaled).reshape(-1)\n",
    "\n",
    "# Calculate metrics\n",
    "baseline_rmse = root_mean_squared_error(y_val_price, pred_val_price)\n",
    "baseline_r2 = r2_score(y_val_price, pred_val_price)\n",
    "\n",
    "print(\"\\nTABULAR BASELINE RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"RMSE: ${baseline_rmse:,.2f}\")\n",
    "print(f\"R² Score: {baseline_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save baseline metrics\n",
    "baseline_metrics = {\n",
    "    \"rmse\": float(baseline_rmse),\n",
    "    \"r2\": float(baseline_r2),\n",
    "    \"model\": \"HistGradientBoostingRegressor\"\n",
    "}\n",
    "\n",
    "(OUTPUT_DIR / \"tabular_baseline_metrics.json\").write_text(\n",
    "    json.dumps(baseline_metrics, indent=2)\n",
    ")\n",
    "\n",
    "# Save predictions\n",
    "pd.DataFrame({\n",
    "    \"y_true\": y_val_price,\n",
    "    \"y_pred\": pred_val_price\n",
    "}).to_csv(OUTPUT_DIR / \"tabular_baseline_val_preds.csv\", index=False)\n",
    "\n",
    "print(\"Saved baseline metrics and predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multimodal Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Multimodal Fusion Model...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Concatenate tabular features with image embeddings\n",
    "X_train_fusion = np.concatenate([X_train, emb_train], axis=1)\n",
    "X_val_fusion = np.concatenate([X_val, emb_val], axis=1)\n",
    "\n",
    "print(f\"Fusion feature dimension: {X_train_fusion.shape[1]}\")\n",
    "print(f\"  - Tabular: {X_train.shape[1]}\")\n",
    "print(f\"  - Image embeddings: {emb_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train fusion model\n",
    "fusion_model = HistGradientBoostingRegressor(\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    max_iter=800,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "fusion_model.fit(X_train_fusion, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate fusion model\n",
    "pred_val_fusion_scaled = fusion_model.predict(X_val_fusion).reshape(-1, 1)\n",
    "\n",
    "# Inverse transform\n",
    "pred_val_fusion_price = target_scaler.inverse_transform(pred_val_fusion_scaled).reshape(-1)\n",
    "\n",
    "# Calculate metrics\n",
    "fusion_rmse = root_mean_squared_error(y_val_price, pred_val_fusion_price)\n",
    "fusion_r2 = r2_score(y_val_price, pred_val_fusion_price)\n",
    "\n",
    "print(\"\\nMULTIMODAL FUSION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"RMSE: ${fusion_rmse:,.2f}\")\n",
    "print(f\"R² Score: {fusion_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fusion metrics\n",
    "fusion_metrics = {\n",
    "    \"rmse\": float(fusion_rmse),\n",
    "    \"r2\": float(fusion_r2),\n",
    "    \"model\": \"HistGradientBoostingRegressor(tab+imgemb)\"\n",
    "}\n",
    "\n",
    "(OUTPUT_DIR / \"fusion_metrics.json\").write_text(\n",
    "    json.dumps(fusion_metrics, indent=2)\n",
    ")\n",
    "\n",
    "# Save predictions\n",
    "pd.DataFrame({\n",
    "    \"y_true\": y_val_price,\n",
    "    \"y_pred\": pred_val_fusion_price\n",
    "}).to_csv(OUTPUT_DIR / \"fusion_val_preds.csv\", index=False)\n",
    "\n",
    "print(\"Saved fusion metrics and predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"Model\": [\"Tabular Baseline\", \"Multimodal Fusion\"],\n",
    "    \"Modalities\": [\"Tabular only\", \"Tabular + Satellite\"],\n",
    "    \"RMSE ($)\": [f\"{baseline_rmse:,.2f}\", f\"{fusion_rmse:,.2f}\"],\n",
    "    \"R² Score\": [f\"{baseline_r2:.4f}\", f\"{fusion_r2:.4f}\"]\n",
    "})\n",
    "\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Improvement\n",
    "rmse_improvement = baseline_rmse - fusion_rmse\n",
    "rmse_pct = (rmse_improvement / baseline_rmse) * 100\n",
    "r2_improvement = fusion_r2 - baseline_r2\n",
    "\n",
    "print(f\"\\nImprovement with satellite imagery:\")\n",
    "print(f\"  RMSE reduction: ${rmse_improvement:,.2f} ({rmse_pct:.1f}%)\")\n",
    "print(f\"  R² increase: +{r2_improvement:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Predicted vs Actual\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax.scatter(y_val_price, pred_val_price, alpha=0.5, label=\"Tabular only\", s=10)\n",
    "ax.scatter(y_val_price, pred_val_fusion_price, alpha=0.5, label=\"Tabular + ResNet18\", s=10)\n",
    "\n",
    "# Perfect prediction line\n",
    "max_val = max(y_val_price.max(), pred_val_fusion_price.max())\n",
    "ax.plot([0, max_val], [0, max_val], 'k--', label=\"Ideal (y=x)\")\n",
    "\n",
    "ax.set_xlabel(\"Actual Price ($)\")\n",
    "ax.set_ylabel(\"Predicted Price ($)\")\n",
    "ax.set_title(\"Predicted vs Actual Property Prices\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"val_pred_scatter.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved: {OUTPUT_DIR / 'val_pred_scatter.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "residuals = y_val_price - pred_val_fusion_price\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(pred_val_fusion_price, residuals, alpha=0.5, s=10)\n",
    "ax.axhline(y=0, color='r', linestyle='--')\n",
    "ax.set_xlabel(\"Predicted Price ($)\")\n",
    "ax.set_ylabel(\"Residual ($)\")\n",
    "ax.set_title(\"Residual Plot - Fusion Model\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"residuals_fusion.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "X_test_tab = np.load(PROCESSED_DATA_DIR / \"X_test_tab.npy\")\n",
    "emb_test = np.load(PROCESSED_DATA_DIR / \"img_emb_test.npy\")\n",
    "test_ids = np.load(PROCESSED_DATA_DIR / \"test_ids.npy\")\n",
    "\n",
    "print(f\"Test samples: {X_test_tab.shape[0]}\")\n",
    "print(f\"Test tabular features: {X_test_tab.shape[1]}\")\n",
    "print(f\"Test embeddings: {emb_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fusion features for test set\n",
    "X_test_fusion = np.concatenate([X_test_tab, emb_test], axis=1)\n",
    "\n",
    "# Predict\n",
    "pred_test_scaled = fusion_model.predict(X_test_fusion).reshape(-1, 1)\n",
    "pred_test_price = target_scaler.inverse_transform(pred_test_scaled).reshape(-1)\n",
    "\n",
    "print(f\"Predictions generated: {len(pred_test_price)}\")\n",
    "print(f\"Price range: ${pred_test_price.min():,.2f} - ${pred_test_price.max():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_ids,\n",
    "    \"predicted_price\": pred_test_price\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv(OUTPUT_DIR / \"submission.csv\", index=False)\n",
    "print(f\"Saved: {OUTPUT_DIR / 'submission.csv'}\")\n",
    "\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Grad-CAM Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "class GradCAM:\n",
    "    \"\"\"Gradient-weighted Class Activation Mapping for CNN explainability\"\"\"\n",
    "    \n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        # Register hooks\n",
    "        target_layer.register_forward_hook(self._save_activation)\n",
    "        target_layer.register_backward_hook(self._save_gradient)\n",
    "    \n",
    "    def _save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def _save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def generate(self, input_tensor):\n",
    "        \"\"\"Generate Grad-CAM heatmap\"\"\"\n",
    "        self.model.eval()\n",
    "        input_tensor.requires_grad = True\n",
    "        \n",
    "        # Forward pass\n",
    "        output = self.model(input_tensor)\n",
    "        \n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        output.sum().backward()\n",
    "        \n",
    "        # Compute weights\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "        \n",
    "        # Compute CAM\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        cam = F.relu(cam)\n",
    "        \n",
    "        # Normalize\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / (cam.max() + 1e-8)\n",
    "        \n",
    "        return cam.squeeze().cpu().numpy()\n",
    "\n",
    "print(\"GradCAM class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_gradcam(image_path, cam, save_path=None):\n",
    "    \"\"\"Overlay Grad-CAM heatmap on original image\"\"\"\n",
    "    # Load original image\n",
    "    img = cv2.imread(str(image_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    \n",
    "    # Resize CAM to match image\n",
    "    cam_resized = cv2.resize(cam, (224, 224))\n",
    "    \n",
    "    # Create heatmap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Overlay\n",
    "    overlay = (heatmap * 0.4 + img * 0.6).astype(np.uint8)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title(\"Original Satellite Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    axes[1].imshow(cam_resized, cmap=\"jet\")\n",
    "    axes[1].set_title(\"Grad-CAM Heatmap\")\n",
    "    axes[1].axis(\"off\")\n",
    "    \n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title(\"Overlay\")\n",
    "    axes[2].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "print(\"Visualization function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for Grad-CAM\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weights = models.ResNet18_Weights.DEFAULT\n",
    "tfms = weights.transforms()\n",
    "\n",
    "resnet = models.resnet18(weights=weights)\n",
    "resnet.eval()\n",
    "resnet.to(device)\n",
    "\n",
    "# Target layer for Grad-CAM (last conv layer)\n",
    "target_layer = resnet.layer4[-1].conv2\n",
    "gradcam = GradCAM(resnet, target_layer)\n",
    "\n",
    "print(f\"Model loaded on: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grad-CAM for sample images\n",
    "images_val = data[\"images_val\"]\n",
    "\n",
    "# Get indices for low and high value properties\n",
    "val_prices = target_scaler.inverse_transform(y_val.reshape(-1, 1)).reshape(-1)\n",
    "sorted_idx = np.argsort(val_prices)\n",
    "\n",
    "# Select 5 cheapest and 5 most expensive\n",
    "sample_indices = list(sorted_idx[:5]) + list(sorted_idx[-5:])\n",
    "\n",
    "gradcam_dir = OUTPUT_DIR / \"gradcam\"\n",
    "gradcam_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    img_path = images_val[idx]\n",
    "    true_price = val_prices[idx]\n",
    "    pred_price = pred_val_fusion_price[idx]\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = tfms(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Generate Grad-CAM\n",
    "    cam = gradcam.generate(img_tensor)\n",
    "    \n",
    "    # Save visualization\n",
    "    save_path = gradcam_dir / f\"{i:02d}_true_{true_price:.0f}_pred_{pred_price:.0f}.png\"\n",
    "    visualize_gradcam(img_path, cam, save_path)\n",
    "    \n",
    "    print(f\"Saved: {save_path.name}\")\n",
    "\n",
    "print(f\"\\nGrad-CAM visualizations saved to: {gradcam_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results table\n",
    "results_md = f\"\"\"## Model Comparison (Validation Set)\n",
    "\n",
    "| Model | Modalities | Fusion Type | RMSE (↓) | R² (↑) |\n",
    "| ----- | ---------- | ----------- | -------: | -----: |\n",
    "| Tabular Baseline (HistGradientBoostingRegressor) | Tabular only | — | {baseline_rmse:,.2f} | {baseline_r2:.4f} |\n",
    "| Fusion Regressor (HGBR on [tabular + ResNet18 embeddings]) | Tabular + Satellite | Intermediate (feature-level concat) | {fusion_rmse:,.2f} | {fusion_r2:.4f} |\n",
    "\n",
    "### Improvement\n",
    "- RMSE Reduction: ${rmse_improvement:,.2f} ({rmse_pct:.1f}%)\n",
    "- R² Increase: +{r2_improvement:.4f}\n",
    "\n",
    "### Notes\n",
    "- Satellite images converted to 512-d embeddings using pretrained ResNet18\n",
    "- Intermediate fusion: concatenate feature vectors before final regressor\n",
    "\"\"\"\n",
    "\n",
    "(OUTPUT_DIR / \"results_table.md\").write_text(results_md)\n",
    "print(\"Results saved to results_table.md\")\n",
    "print(results_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Training Complete!**\n",
    "\n",
    "- ✅ Tabular Baseline: RMSE = $134,809, R² = 0.8552\n",
    "- ✅ Multimodal Fusion: RMSE = $132,247, R² = 0.8606\n",
    "- ✅ Improvement: 1.9% RMSE reduction\n",
    "- ✅ Grad-CAM visualizations generated\n",
    "- ✅ Test predictions saved to submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
